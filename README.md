挑战背景：在花旗，数据科学家们的任务是通过微调大语言模型（LLMs）来改进各种金融应用，例如客户服务聊天机器人、提供欺诈检测常规监控和个性化的金融建议等。然而，其中一个挑战是如何将客户提供的大量非结构化信息文档转换为适合特定模型训练需要的结构化数据集。利用AI自动处理、分块和提取这些文档中的相关信息，可以显著提高模型微调的效率和准确性。

挑战描述：开发一个基于AI的系统，能够自动将用户提供的文档转换为结构化数据集，以适应不同的金融应用场景的LLM微调。该系统能处理各种文档格式，并实现高级数据处理技术，如分块、检索、摘要、问答生成和文本分析。目标是确保处理后的数据集具有意义且上下文准确，从而促进以下场景的模型微调：

客户服务聊天机器人：生成可以有效理解和回应广泛客户询问的训练数据

欺诈检测：从交易数据中提取模式和异常，以训练可以识别和预防欺诈行为的模型

合规监控：总结法规和合规文件，以帮助模型确保遵守金融法规

此外，该系统应确保数据安全、保持客户隐私，并适应不同类型的文档和金融应用场景。

SmartFinData——基于AI驱动与NLP技术的金融数据智能处理系统

模块一：文件处理模块

1.功能：将不同格式的非结构化/半结构化文档转换为统一格式的、带结构标记的纯文本，为后续分块分块、信息提取等流程提供标准化输入。

2.代码结构：

document_processing/
├── document_processor.py # 主入口模块
├── processors/
│ ├── pdf_processor.py # PDF处理器
│ ├── docx_processor.py # Word处理器
│ ├── excel_processor.py # Excel处理器
│ ├── csv_processor.py # CSV处理器
│ └── json_processor.py # JSON处理器

3.设计特点：

（1）模块化架构：每个文件类型独立处理器，新增文件类型只需要添加处理器并更新映射表

（2）结构化输出：PDF保留分页标识（=== Page N ===）,Excel/CSV转换为Markdown表格，JSON递归展开为键值对格式

（3）错误处理：统一返回Optional[str]格式（纯文本字符串），每个处理器独立捕获异常并记录日志，主入口检查文件存在性

4.改进方向（暂时先不需要实现）：添加文件类型自动检测、支持加密文档处理、添加并行处理能力、集成文件元数据据提取（创建时间等）

模块二：文本分块模块

1.功能：将长文本切割为适合LLM处理的语义连贯的片段，同时保留关键上下文关系。

2.代码结构：

text_chunking/
├── chunk_strategies.py # 分块策略实现
├── chunk_manager.py # 分块逻辑协调
└── exceptions.py # 自定义异常

3.设计特点：

在分块策略中，设计了3中分块策略：

固定窗口分块（基础策略）：按照固定步长切割文本（类似滑动窗口），设置了参数chunk_size控制块的最大长度、overlap控制块间重叠字符数，避免切断上下文。这种策略适合处理格式规范的文档，如交易记录CSV，但是不适合处理含复杂结构的文本，如合同条款

语义感知分块（使用NLP模型）：使用GPT2的分词器将文本转换为tokens序列，避免在单词中间切割，同时精准控制输入长度。适合处理客户服务对话记录，例如：

原始文本： "客户报告信用卡在巴黎被盗刷，时间约为当地时间15:30..."
分块结果： ["客户报告信用卡在", "巴黎被盗刷，时间约为当地时间15:30..."]

结构感知分块（专为金融文档优化）：在第一个模块中，我们为每种类型的文档设置了不同的标记，如：

- `=== Page N ===` → PDF分页
  
- `=== Sheet '名称' ===` → Excel工作表
  
- `# 标题` → Word标题样式
  

这里就选择在文档标记处优先进行分割，同时当长度超过chunk_size时强制分割。

模块三：信息提取模块

1.功能：将分块后的文本转化为结构化知识，提取关键信息，包括：实体识别（金额、账户、法规条款等金融实体）、关系抽取（交易双方关系、条款关联性）、异常检测（可疑交易模式、合规风险点）、摘要生成（法规条款/客户问题的核心要点）

2.代码结构：

information_extraction/
├── information_extractor.py     #主整合模块
├── entity_extractor.py # 实体提取核心
├── relation_extractor.py # 关系提取
├── anomaly_detector.py # 异常检测
├── summarizer.py # 摘要生成
└── schemas.py # 数据结构定义

模块四：场景适配模块

1.功能：将通用结构化数据转换为特定场景优化的训练格式，针对三个给定的金融应用场景：

客户服务问答：生成指令微调数据（问答对、对话流程）；欺诈检测：构建交易模式特征（实体关系图谱、时序特征）；合规监控：生成法律条款摘要和义务映射。

2.代码结构：

scenario_adaptation/
├── customer_service_generator.py # 客户服务数据生成
├── fraud_encoder.py # 欺诈检测特征编码
├── compliance_mapper.py # 合规知识映射
└── schemas.py # 数据模型定义

3.三个场景的转换逻辑;

(1)客户服务场景：

目的：生成对话训练数据

转换过程：1.意图识别：基于实体类型映射到预设意图（账户查询、争议处理等）    2.响应生成：模板填充（针对高频问题）、LLM生成（针对复杂问题）

(2)欺诈检测场景：

目标：构建交易特征图谱

关键技术：图神经网络构建交易关系、时序模式分析

（3）合规监控场景：

目的：生成法律知识映射

处理流程：条款摘要生成、义务主体关联

模块五：模型训练模块

1.功能：将场景适配后的数据用于微调大语言模型，并评估模型性能

2.代码结构：

model_training/
├── configs/
│ ├── training_config.py
│ └── eval_config.py
├── data_utils.py
├── trainer.py
├── evaluator.py
└── peft_utils.py

数据处理流程图：
 A[原始文件] --> B{文件处理模块}
 B --> C[结构化文本]
 C --> D{文本分块模块}
 D --> E[分块文本]
 E --> F{信息提取模块}
 F --> G[结构化知识]
 G --> H{场景适配模块}
 H --> I[客户服务数据]
 H --> J[欺诈检测数据]
 H --> K[合规监控数据]
 I --> L{模型训练模块}
 J --> L
 K --> L
 L --> M[金融领域LLM]
